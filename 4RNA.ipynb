{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP NEURAL NETWORK "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "sns.set_theme(style='darkgrid', palette='hls')\n",
    "\n",
    "import torch \n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        X_data = X_data\n",
    "        Y_data = Y_data\n",
    "        self.x, self.y = self.clean(X_data, Y_data)\n",
    "        self.samples = self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "\n",
    "    def clean(self,X_data,Y_data):\n",
    "        scaler = StandardScaler()\n",
    "        data_x = scaler.fit_transform(X_data)\n",
    "        x = torch.from_numpy(data_x).float()\n",
    "        y = torch.from_numpy(Y_data.values).float()\n",
    "        y = y[:,None]\n",
    "        return x,y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (5482, 99) y_train (5482,) \n",
      "X_test (1371, 99) y_test (1371,)\n"
     ]
    }
   ],
   "source": [
    "file = './data_processed/embeddings_spacy.csv'\n",
    "data = pd.read_csv(file, index_col=0)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data[data.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20, shuffle=True)\n",
    "\n",
    "print(\"X_train {} y_train {} \\nX_test {} y_test {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "dataset_train = Dataset_Custom(X_train, y_train)\n",
    "dataset_test = Dataset_Custom(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataLoaders for both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "\n",
    "trainloader = DataLoader(dataset=dataset_train, batch_size=batch, shuffle=True)\n",
    "testloader = DataLoader(dataset=dataset_test, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, hidden_sizes, output_size, activation_functions):\n",
    "    layers = []\n",
    "    layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        layers.append(('fc{}'.format(i), nn.Linear(layer_sizes[i-1], layer_sizes[i])))\n",
    "        if activation_functions[i-1] == 'relu':\n",
    "            layers.append(('relu{}'.format(i), nn.ReLU()))\n",
    "        elif activation_functions[i-1] == 'sigmoid':\n",
    "            layers.append(('sigmoid{}'.format(i), nn.Sigmoid()))\n",
    "\n",
    "    model = nn.Sequential(OrderedDict(layers))\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of loss, learning rate & epochs\n",
    "def train_rna(model):\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    epochs = 100\n",
    "    #print_every = int((X_train.shape[0]/batch) / 20)\n",
    "    #steps = 0 \n",
    "    #list_loss = []\n",
    "    #list_loss_test = []\n",
    "    #list_epochs = []\n",
    "\n",
    "    # Comenzando entrenamiento. . . \n",
    "    for e in range(epochs):\n",
    "        #running_loss = 0\n",
    "        # En cada epoca cargamos todos los batches \n",
    "        for inputs, labels in iter(trainloader):\n",
    "            #steps += 1\n",
    "            # Reiniciar los gradientes\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model.forward(inputs)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backprogation\n",
    "            loss.backward()\n",
    "            # Actualiza los pesos de acuerdo a un paso del optimizador\n",
    "            optimizer.step()\n",
    "            # Guardamos la perdida para control del entrenamiento\n",
    "            #running_loss += loss.item()\n",
    "            # imprimimos cada 20% lotes\n",
    "            #if steps % print_every == 0:\n",
    "            #    list_loss.append(running_loss/print_every)\n",
    "            #    running_loss = 0\n",
    "                \n",
    "            #    output_test = model.forward(dataset_test.x)\n",
    "            #    loss_t = criterion(output_test, dataset_test.y)\n",
    "            #    list_loss_test.append(loss_t.item())\n",
    "            #    list_epochs.append(e+1)\n",
    "            \n",
    "    #df = pd.DataFrame()\n",
    "    #df['epochs'] = list_epochs\n",
    "    #df['loss_train'] = list_loss\n",
    "    #df['loss_test'] = list_loss_test\n",
    "\n",
    "    #sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    #sns.lineplot(x=\"epochs\", y=\"loss_train\", data=df, color='yellow', label='Entrenamiento')\n",
    "    #sns.lineplot(x=\"epochs\", y=\"loss_test\", data=df, color='violet', label='Prueba')\n",
    "\n",
    "    output_acc = model.forward(dataset_test.x)\n",
    "\n",
    "    # Medidas\n",
    "    pred = torch.unsqueeze(torch.tensor([ 0 if p<=0.5 else 1 for p in output_acc]),1)\n",
    "    label = dataset_test.y\n",
    "    pred = pred.numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "    # Calcular la exactitud\n",
    "    exactitud = round(accuracy_score(label, pred),2)\n",
    "    #print(\"Exactitud:\", exactitud)\n",
    "\n",
    "    # Calcular la preci sión\n",
    "    precision = round(precision_score(label, pred),2)\n",
    "    #print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular la puntuación F1\n",
    "    f1 = round(f1_score(label, pred),2)\n",
    "    #print(\"Puntuación F1:\", f1)\n",
    "\n",
    "    mean_scores = round(((exactitud + precision + f1)/3),4)\n",
    "    return mean_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo genético para optimizar la estructura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generacion  0\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [41, 48], 'activation': ['relu', 'relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  1\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [40], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  2\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [17, 43, 22], 'activation': ['relu', 'relu', 'relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  3\n",
      "Mejor aptitud para esta generación:  0.5533\n",
      "{'input_size': 99, 'hidden_sizes': [22], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5533}\n",
      "Generacion  4\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [32], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  5\n",
      "Mejor aptitud para esta generación:  0.55\n",
      "{'input_size': 99, 'hidden_sizes': [40], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.55}\n",
      "Generacion  6\n",
      "Mejor aptitud para esta generación:  0.5767\n",
      "{'input_size': 99, 'hidden_sizes': [22], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5767}\n",
      "Generacion  7\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [50], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  8\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [40], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  9\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [29], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  10\n",
      "Mejor aptitud para esta generación:  0.5733\n",
      "{'input_size': 99, 'hidden_sizes': [29], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5733}\n",
      "Generacion  11\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [41], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  12\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [29], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  13\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [10], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  14\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [17], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  15\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [35], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  16\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [10], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  17\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [45], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  18\n",
      "Mejor aptitud para esta generación:  0.57\n",
      "{'input_size': 99, 'hidden_sizes': [42], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.57}\n",
      "Generacion  19\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [32], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  20\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [42], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  21\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [26], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  22\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [15], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  23\n",
      "Mejor aptitud para esta generación:  0.57\n",
      "{'input_size': 99, 'hidden_sizes': [18], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.57}\n",
      "Generacion  24\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [18], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  25\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [16], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  26\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [46], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  27\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [44], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  28\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [44], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  29\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [10], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  30\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [26], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  31\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [22], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  32\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [4], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  33\n",
      "Mejor aptitud para esta generación:  0.5533\n",
      "{'input_size': 99, 'hidden_sizes': [26], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5533}\n",
      "Generacion  34\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [47], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  35\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [33], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  36\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [26], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  37\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [49], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  38\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [37], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  39\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  40\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [39], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  41\n",
      "Mejor aptitud para esta generación:  0.5767\n",
      "{'input_size': 99, 'hidden_sizes': [22], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5767}\n",
      "Generacion  42\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  43\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [39], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  44\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [39], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  45\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [40], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  46\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  47\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [11], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  48\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [48], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  49\n",
      "Mejor aptitud para esta generación:  0.5633\n",
      "{'input_size': 99, 'hidden_sizes': [11], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5633}\n",
      "Generacion  50\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [48], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  51\n",
      "Mejor aptitud para esta generación:  0.57\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.57}\n",
      "Generacion  52\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [11], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  53\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [11], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  54\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [32], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  55\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  56\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  57\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  58\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [10], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  59\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  60\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [10], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  61\n",
      "Mejor aptitud para esta generación:  0.5567\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5567}\n",
      "Generacion  62\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [28], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  63\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  64\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  65\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [27], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  66\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [20], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  67\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [48], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  68\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [43], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n",
      "Generacion  69\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [43], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  70\n",
      "Mejor aptitud para esta generación:  0.56\n",
      "{'input_size': 99, 'hidden_sizes': [43], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.56}\n",
      "Generacion  71\n",
      "Mejor aptitud para esta generación:  0.57\n",
      "{'input_size': 99, 'hidden_sizes': [44], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.57}\n",
      "Generacion  72\n",
      "Mejor aptitud para esta generación:  0.5667\n",
      "{'input_size': 99, 'hidden_sizes': [48], 'activation': ['relu', 'sigmoid'], 'output_size': 1, 'fit': 0.5667}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 126\u001b[0m\n\u001b[1;32m    124\u001b[0m individuos \u001b[39m=\u001b[39m CrossoverAndMutation(individuos)\n\u001b[1;32m    125\u001b[0m networks \u001b[39m=\u001b[39m generateNetworks(individuos) \n\u001b[0;32m--> 126\u001b[0m individuos \u001b[39m=\u001b[39m fitness(networks, individuos)\n\u001b[1;32m    127\u001b[0m noGeneracion \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGeneracion \u001b[39m\u001b[39m'\u001b[39m,noGeneracion)\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36mfitness\u001b[0;34m(networks, individuos)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfitness\u001b[39m(networks:\u001b[39mlist\u001b[39m, individuos):\n\u001b[1;32m     36\u001b[0m     \u001b[39mfor\u001b[39;00m no \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(no_individuos):\n\u001b[0;32m---> 37\u001b[0m         individuos[no][\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_rna(networks[no])  \n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m individuos\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mtrain_rna\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m#print_every = int((X_train.shape[0]/batch) / 20)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#steps = 0 \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#list_loss = []\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# Comenzando entrenamiento. . . \u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     17\u001b[0m     \u001b[39m#running_loss = 0\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# En cada epoca cargamos todos los batches \u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(trainloader):\n\u001b[1;32m     20\u001b[0m         \u001b[39m#steps += 1\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[39m# Reiniciar los gradientes\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generacion de la poblacion inicial\n",
    "# 5 redes 1 capa oculta , 5 redes 2 capa oculta , 5 redes 3 capa oculta , 5 redes 4 capa oculta\n",
    "# No. Neuronas por capa (3, 50)\n",
    "no_individuos = 20\n",
    "input_size = X.shape[1]\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "individuos = []\n",
    "# -------------------------- Generacion de la poblacion inicial -----------------------------------------\n",
    "\n",
    "# Generamos las caracteristicas de los individuos\n",
    "for i in range(4):\n",
    "    # Redes\n",
    "    for j in range(5):\n",
    "        individuo = {'input_size': input_size ,'hidden_sizes':[] , 'activation':[], 'output_size' : output_size , 'fit' : 0.0}\n",
    "        for k in range(i+1):\n",
    "            individuo['hidden_sizes'].append(np.random.randint(3,51))\n",
    "            individuo['activation'].append('relu')\n",
    "        individuo['activation'].append('sigmoid')\n",
    "        individuos.append(individuo)\n",
    "\n",
    "# -------------------------- Funcion para generar los modelos a partir de sus caracteristicas ---------------\n",
    "\n",
    "# Generamos los individuos en base a las caracteristicas\n",
    "def generateNetworks(individuos):\n",
    "    networks = []\n",
    "    for item in individuos:\n",
    "        networks.append(build_model(item['input_size'], item['hidden_sizes'] , item['output_size'], item['activation']))\n",
    "    return networks\n",
    "\n",
    "# -------------------------- Evaluacion del modelo -------------------\n",
    "\n",
    "# Evaluation\n",
    "def fitness(networks:list, individuos):\n",
    "    for no in range(no_individuos):\n",
    "        individuos[no]['fit'] = train_rna(networks[no])  \n",
    "    return individuos\n",
    "\n",
    "# -------------------------- Seleccion (7 mejores y 3 peores) -------------------\n",
    "\n",
    "# Selection\n",
    "def selection(individuos):\n",
    "    individuos = sorted(individuos, key=lambda x: x['fit'], reverse=True)\n",
    "    # Se seleccionan los mejores 7 y los ultimos 3 \n",
    "    individuos = individuos[0:7] + individuos[-3:]\n",
    "    return individuos\n",
    "\n",
    "# -------------------------- Cruza y mutacion -------------------\n",
    "\n",
    "def CrossoverAndMutation(individuos):\n",
    "    # Aleatorizamos los individuos seleccionados para agregar diversidad y evitar elitismo\n",
    "    # Cross-over and mutation 5 new -> cross over 5 -> mutation\n",
    "    random.shuffle(individuos)\n",
    "\n",
    "    # Cross-over\n",
    "    for i in range(0,10,2):\n",
    "        individuo = {'input_size': input_size ,'hidden_sizes':[] , 'activation':[], 'output_size' : output_size , 'fit' : 0.0}\n",
    "        # Aleatoria un numero para saber que capas va a heredar\n",
    "        if np.random.randint(0,2) == 0:\n",
    "            individuo['hidden_sizes'] = individuos[i]['hidden_sizes'].copy()\n",
    "            individuo['activation'] = individuos[i]['activation'].copy()\n",
    "            individuo['hidden_sizes'][np.random.randint(0,len(individuo['hidden_sizes']))] = individuos[i+1]['hidden_sizes'][np.random.randint(0,len(individuos[i+1]['hidden_sizes']))]\n",
    "        else :\n",
    "            individuo['hidden_sizes'] = individuos[i+1]['hidden_sizes'].copy()\n",
    "            individuo['activation'] = individuos[i+1]['activation'].copy()\n",
    "            individuo['hidden_sizes'][np.random.randint(0,len(individuo['hidden_sizes']))] = individuos[i]['hidden_sizes'][np.random.randint(0,len(individuos[i]['hidden_sizes']))]\n",
    "        \n",
    "        individuos.append(individuo)\n",
    "        \n",
    "    # Mutations\n",
    "    mutations = []\n",
    "    while len(mutations) != 5:\n",
    "        index = np.random.randint(0,10)\n",
    "        if len(mutations) == 0:\n",
    "            mutations.append(index)\n",
    "        else:\n",
    "            if index not in mutations:\n",
    "                mutations.append(index)\n",
    "    # Copiar un gen == 1 \n",
    "    # Crear nuevo gen == 0\n",
    "    for mutation in mutations:\n",
    "        individuo = {'input_size': input_size ,'hidden_sizes':[] , 'activation':[], 'output_size' : output_size , 'fit' : 0.0}\n",
    "        individuo['hidden_sizes'] = individuos[mutation]['hidden_sizes'].copy()\n",
    "        individuo['activation'] = individuos[mutation]['activation'].copy()\n",
    "\n",
    "        if np.random.randint(0,2) == 0 or len(individuo['hidden_sizes']) == 1:\n",
    "            individuo['hidden_sizes'][np.random.randint(0,len(individuo['hidden_sizes']))] = np.random.randint(3,51)\n",
    "        else:\n",
    "            id_ = np.random.randint(0,len(individuo['hidden_sizes']))\n",
    "            id_new = np.random.randint(0,len(individuo['hidden_sizes']))\n",
    "            while id_ == id_new:\n",
    "                id_new = np.random.randint(0,len(individuo['hidden_sizes']))\n",
    "            individuo['hidden_sizes'][id_] = individuo['hidden_sizes'][id_new]\n",
    "\n",
    "        individuos.append(individuo)\n",
    "        \n",
    "    return individuos\n",
    "\n",
    "def criteria(individuos):\n",
    "    individuos = sorted(individuos, key=lambda x: x['fit'], reverse=True)\n",
    "    print('Mejor aptitud para esta generación: ', individuos[0]['fit'])\n",
    "    print(individuos[0])\n",
    "    if individuos[0]['fit'] >= 0.65:\n",
    "        file = open('./GeneticsResults.txt', mode='w',encoding='utf-8')\n",
    "        file.write('Arquitectura encontrada!\\n')\n",
    "        file.write(str(individuos[0]))\n",
    "        file.close()\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "# -------------------------- ALGORITMO GENETICO -------------------\n",
    "\n",
    "# Evaluar la poblacion inicial\n",
    "\n",
    "noGeneracion = 0\n",
    "networks = generateNetworks(individuos) # Generar modelos usando caracteristicas\n",
    "individuos = fitness(networks, individuos) # Evaluamos cada modelo\n",
    "print('Generacion ',noGeneracion)\n",
    "paro = criteria(individuos)\n",
    "while not paro:\n",
    "    individuos = selection(individuos) # Seleccionamos los mejores\n",
    "    individuos = CrossoverAndMutation(individuos)\n",
    "    networks = generateNetworks(individuos) \n",
    "    individuos = fitness(networks, individuos)\n",
    "    noGeneracion += 1\n",
    "    print('Generacion ',noGeneracion)\n",
    "    paro = criteria(individuos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
