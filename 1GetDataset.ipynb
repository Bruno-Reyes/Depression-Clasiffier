{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "from typing import List, Dict\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://s3-ceatic.ujaen.es:8036/\" \n",
    "TOKEN = \"faae943b33e3f5947d122fd9ebca17727fbfbce5\" \n",
    "\n",
    "# Download endpoints\n",
    "ENDPOINT_DOWNLOAD_MESSAGES_TRIAL = URL+\"{TASK}/download_trial/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_GOLD_TRIAL = URL+\"{SUBTASK}/download_trial/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_MESSAGES_TRAIN = URL+\"{TASK}/download_train/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_GOLD_TRAIN = URL+\"{SUBTASK}/download_train/{TOKEN}\"\n",
    "\n",
    "# Trial endpoints\n",
    "ENDPOINT_GET_MESSAGES_TRIAL = URL+\"{TASK}/getmessages_trial/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"{SUBTASK}/submit_trial/{TOKEN}/{RUN}\"\n",
    "\n",
    "# Test endpoints\n",
    "ENDPOINT_GET_MESSAGES = URL+\"{TASK}/getmessages/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS = URL+\"{SUBTASK}/submit/{TOKEN}/{RUN}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_messages_trial(task: str,subtasks:List[str], token: str) -> List[Dict]:\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRIAL.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n",
    "\n",
    "    for subtask in subtasks:\n",
    "        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRIAL.format(SUBTASK=subtask, TOKEN=token))\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "        else:\n",
    "          file_object = open(\"./data/{task}/trial/gold_trial_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n",
    "          file_object.write(response.text)\n",
    "\n",
    "def download_messages_train(task: str,subtasks:List[str], token: str) -> List[Dict]:\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRAIN.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/subjects_train/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/subjects_train/\".format(task=task))\n",
    "\n",
    "    for subtask in subtasks:\n",
    "        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRAIN.format(SUBTASK=subtask, TOKEN=token))\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "        else:\n",
    "          file_object = open(\"./data/{task}/trial/gold_train_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n",
    "          file_object.write(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_taskX:\n",
    "    def __init__(self, task: str, subtasks: List[str], token: str, number_of_runs: int, tracker: EmissionsTracker):\n",
    "        # Task in which you participate\n",
    "        self.task = task\n",
    "        # Subtasks in which you participate\n",
    "        self.subtasks = subtasks\n",
    "        # Token identifier\n",
    "        self.token = token\n",
    "        # Number of runs (Max: 3)\n",
    "        self.number_of_runs = number_of_runs\n",
    "        # Object to calculate CO2 emissions\n",
    "        self.tracker = tracker\n",
    "        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy', 'ram_energy', \n",
    "            'energy_consumed', 'cpu_count', 'gpu_count', 'cpu_model', 'gpu_model', 'ram_total_size']\n",
    "\n",
    "    # Here a GET request is sent to the server to extract the data.\n",
    "    def get_messages(self, retries: int, backoff: float) -> Dict:\n",
    "        session = requests.Session()\n",
    "        retries = Retry( \n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token))\n",
    "        if response.status_code != 200:\n",
    "          print(\"GET - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "          return []\n",
    "        else:\n",
    "          return json.loads(response.content)\n",
    "\n",
    "    # The POST requests are sent to the server to send predictions and carbon emission data\n",
    "    def submit_decission(self, subtask: int, messages: List[Dict], emissions:Dict, retries, backoff):\n",
    "        decisions = {}\n",
    "\n",
    "        # You must create the appropriate structure to send the predictions according to each subtask\n",
    "        for message in messages:\n",
    "            decisions[message[\"nick\"]] = random.randint(0, 1) # the decision of your system according to subtask\n",
    "\n",
    "        data = {\n",
    "            \"predictions\": decisions,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "\n",
    "        data = json.dumps(data)\n",
    "        # Session to POST request\n",
    "        session = requests.Session()\n",
    "        retries = Retry(\n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "        for run in range(0,self.number_of_runs):\n",
    "            # For each run, new decisions\n",
    "            response = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(SUBTASK=self.subtasks[subtask], TOKEN=self.token, RUN=run), json=[data])\n",
    "            if response.status_code != 200:\n",
    "                print(\"POST - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "            else:\n",
    "                print(\"Subtask {}: - run {}\".format(self.subtasks[subtask], run))\n",
    "        \n",
    "\n",
    "    # Main thread\n",
    "    def run_taskX(self, retries: int, backoff: float):\n",
    "        # Get messages for taskX\n",
    "        messages = self.get_messages(retries, backoff)\n",
    "        # If there are no messages\n",
    "        if len(messages) == 0:\n",
    "            print(\"All rounds processed\")\n",
    "            return\n",
    "\n",
    "        while len(messages) > 0:\n",
    "            print(\"------------------- Processing round {}\".format(messages[0][\"round\"]))\n",
    "            # Save subjects\n",
    "            with open('./data/rounds_trial/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n",
    "                json.dump(messages, json_file, ensure_ascii=False)\n",
    "\n",
    "            # Calculate emissions for each prediction\n",
    "            self.tracker.start()\n",
    "\n",
    "            # Your code\n",
    "            \n",
    "            emissions = self.tracker.stop()\n",
    "            df = pd.read_csv(\"emissions.csv\")\n",
    "            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
    "\n",
    "            self.submit_decission(0, messages, measurements, retries, backoff) # taskXa\n",
    "            self.submit_decission(1, messages, measurements, retries, backoff) # taskXb\n",
    "            self.submit_decission(2, messages, measurements, retries, backoff) # taskXc\n",
    "            self.submit_decission(3, messages, measurements, retries, backoff) # taskXd\n",
    "\n",
    "            # Only one GET request for each round\n",
    "            messages = self.get_messages(retries, backoff)\n",
    "\n",
    "        print(\"All rounds processed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    download_messages_trial(\"task2\", [\"task2a\"], TOKEN)\n",
    "    download_messages_train(\"task2\", [\"task2a\"], TOKEN)\n",
    "\n",
    "def get_post_data():\n",
    "    # Emissions Tracker Config\n",
    "    config = {\n",
    "        \"save_to_file\": True,\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"tracking_mode\": \"process\",\n",
    "        \"output_dir\": \".\", \n",
    "    }\n",
    "    tracker = EmissionsTracker(**config)\n",
    "\n",
    "    number_runs = 3 # Max: 3\n",
    "\n",
    "    # Prediction period\n",
    "    client_taskX = Client_taskX(\"task2\", [\"task2a\"], TOKEN, number_runs, tracker)\n",
    "    client_taskX.run_taskX(5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()\n",
    "#get_post_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
