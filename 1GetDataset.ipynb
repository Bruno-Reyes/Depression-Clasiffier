{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "from typing import List, Dict\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://s3-ceatic.ujaen.es:8036/\" \n",
    "TOKEN = \"faae943b33e3f5947d122fd9ebca17727fbfbce5\" \n",
    "\n",
    "# Download endpoints\n",
    "ENDPOINT_DOWNLOAD_MESSAGES_TRIAL = URL+\"{TASK}/download_trial/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_GOLD_TRIAL = URL+\"{SUBTASK}/download_trial/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_MESSAGES_TRAIN = URL+\"{TASK}/download_train/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_GOLD_TRAIN = URL+\"{SUBTASK}/download_train/{TOKEN}\"\n",
    "\n",
    "# Trial endpoints\n",
    "ENDPOINT_GET_MESSAGES_TRIAL = URL+\"{TASK}/getmessages_trial/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"{SUBTASK}/submit_trial/{TOKEN}/{RUN}\"\n",
    "\n",
    "# Test endpoints\n",
    "ENDPOINT_GET_MESSAGES = URL+\"{TASK}/getmessages/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS = URL+\"{SUBTASK}/submit/{TOKEN}/{RUN}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_messages_trial(task: str,subtasks:List[str], token: str) -> List[Dict]:\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRIAL.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n",
    "\n",
    "    for subtask in subtasks:\n",
    "        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRIAL.format(SUBTASK=subtask, TOKEN=token))\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "        else:\n",
    "          file_object = open(\"./data/{task}/trial/gold_trial_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n",
    "          file_object.write(response.text)\n",
    "\n",
    "def download_messages_train(task: str,subtasks:List[str], token: str) -> List[Dict]:\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRAIN.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/subjects_train/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/subjects_train/\".format(task=task))\n",
    "\n",
    "    for subtask in subtasks:\n",
    "        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRAIN.format(SUBTASK=subtask, TOKEN=token))\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "        else:\n",
    "          file_object = open(\"./data/{task}/trial/gold_train_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n",
    "          file_object.write(response.text)\n",
    "\n",
    "def download_messages_test(task: str,subtasks:List[str], token: str) -> List[Dict]:\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRAIN.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/subjects_test/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/subjects_test/\".format(task=task))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_taskX:\n",
    "    def __init__(self, task: str, subtasks: List[str], token: str, number_of_runs: int, tracker: EmissionsTracker):\n",
    "        # Task in which you participate\n",
    "        self.task = task\n",
    "        # Subtasks in which you participate\n",
    "        self.subtasks = subtasks\n",
    "        # Token identifier\n",
    "        self.token = token\n",
    "        # Number of runs (Max: 3)\n",
    "        self.number_of_runs = number_of_runs\n",
    "        # Object to calculate CO2 emissions\n",
    "        self.tracker = tracker\n",
    "        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy', 'ram_energy', \n",
    "            'energy_consumed', 'cpu_count', 'gpu_count', 'cpu_model', 'gpu_model', 'ram_total_size']\n",
    "\n",
    "    # Here a GET request is sent to the server to extract the data.\n",
    "    def get_messages(self, retries: int, backoff: float) -> Dict:\n",
    "        session = requests.Session()\n",
    "        retries = Retry( \n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token))\n",
    "        if response.status_code != 200:\n",
    "          print(\"GET - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "          return []\n",
    "        else:\n",
    "          return json.loads(response.content)\n",
    "\n",
    "    # The POST requests are sent to the server to send predictions and carbon emission data\n",
    "    def submit_decission(self, subtask: int, messages: List[Dict], emissions:Dict, retries, backoff):\n",
    "        decisions = {}\n",
    "\n",
    "        # You must create the appropriate structure to send the predictions according to each subtask\n",
    "        for message in messages:\n",
    "            decisions[message[\"nick\"]] = random.randint(0, 1) # the decision of your system according to subtask\n",
    "\n",
    "        data = {\n",
    "            \"predictions\": decisions,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "\n",
    "        data = json.dumps(data)\n",
    "        # Session to POST request\n",
    "        session = requests.Session()\n",
    "        retries = Retry(\n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "        for run in range(0,self.number_of_runs):\n",
    "            # For each run, new decisions\n",
    "            response = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(SUBTASK=self.subtasks[subtask], TOKEN=self.token, RUN=run), json=[data])\n",
    "            if response.status_code != 200:\n",
    "                print(\"POST - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "            else:\n",
    "                print(\"Subtask {}: - run {}\".format(self.subtasks[subtask], run))\n",
    "        \n",
    "\n",
    "    # Main thread\n",
    "    def run_taskX(self, retries: int, backoff: float):\n",
    "        # Get messages for taskX\n",
    "        messages = self.get_messages(retries, backoff)\n",
    "        # If there are no messages\n",
    "        if len(messages) == 0:\n",
    "            print(\"All rounds processed\")\n",
    "            return\n",
    "\n",
    "        while len(messages) > 0:\n",
    "            print(\"------------------- Processing round {}\".format(messages[0][\"round\"]))\n",
    "            # Save subjects\n",
    "            with open('./data/rounds_trial/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n",
    "                json.dump(messages, json_file, ensure_ascii=False)\n",
    "\n",
    "            \"\"\"# Calculate emissions for each prediction\n",
    "            self.tracker.start()\n",
    "\n",
    "            # Your code\n",
    "            \n",
    "\n",
    "            emissions = self.tracker.stop()\n",
    "            df = pd.read_csv(\"emissions.csv\")\n",
    "            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
    "\n",
    "            self.submit_decission(0, messages, measurements, retries, backoff) # taskXa\n",
    "            self.submit_decission(1, messages, measurements, retries, backoff) # taskXb\n",
    "            self.submit_decission(2, messages, measurements, retries, backoff) # taskXc\n",
    "            self.submit_decission(3, messages, measurements, retries, backoff) # taskXd\n",
    "            \n",
    "            # Only one GET request for each round\n",
    "            messages = self.get_messages(retries, backoff)\n",
    "            \"\"\"\n",
    "        print(\"All rounds processed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    download_messages_trial(\"task2\", [\"task2a\"], TOKEN)\n",
    "    download_messages_train(\"task2\", [\"task2a\"], TOKEN)\n",
    "\n",
    "def get_post_data():\n",
    "    # Emissions Tracker Config\n",
    "    config = {\n",
    "        \"save_to_file\": True,\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"tracking_mode\": \"process\",\n",
    "        \"output_dir\": \".\", \n",
    "    }\n",
    "    tracker = EmissionsTracker(**config)\n",
    "\n",
    "    number_runs = 3 # Max: 3\n",
    "\n",
    "    # Prediction period\n",
    "    client_taskX = Client_taskX(\"task2\", [\"task2a\"], TOKEN, number_runs, tracker)\n",
    "    client_taskX.run_taskX(5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './data/task2/trial/subjects_trial/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m download_data()\n\u001b[1;32m      2\u001b[0m \u001b[39m#get_post_data()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mdownload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_data\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     download_messages_trial(\u001b[39m\"\u001b[39;49m\u001b[39mtask2\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m\"\u001b[39;49m\u001b[39mtask2a\u001b[39;49m\u001b[39m\"\u001b[39;49m], TOKEN)\n\u001b[1;32m      3\u001b[0m     download_messages_train(\u001b[39m\"\u001b[39m\u001b[39mtask2\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtask2a\u001b[39m\u001b[39m\"\u001b[39m], TOKEN)\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mdownload_messages_trial\u001b[0;34m(task, subtasks, token)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m   z \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39mZipFile(io\u001b[39m.\u001b[39mBytesIO(response\u001b[39m.\u001b[39mcontent))\n\u001b[0;32m----> 8\u001b[0m   os\u001b[39m.\u001b[39;49mmakedirs(\u001b[39m\"\u001b[39;49m\u001b[39m./data/\u001b[39;49m\u001b[39m{task}\u001b[39;49;00m\u001b[39m/trial/subjects_trial/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(task\u001b[39m=\u001b[39;49mtask))\n\u001b[1;32m      9\u001b[0m   z\u001b[39m.\u001b[39mextractall(\u001b[39m\"\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{task}\u001b[39;00m\u001b[39m/trial/subjects_trial/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(task\u001b[39m=\u001b[39mtask))\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m subtask \u001b[39min\u001b[39;00m subtasks:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './data/task2/trial/subjects_trial/'"
     ]
    }
   ],
   "source": [
    "#download_data()\n",
    "#get_post_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_messages_test(\"task2\", [\"task2a\"], TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
